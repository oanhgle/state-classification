{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cis4930-state-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u-alBlmq5IUC",
        "outputId": "e45231ba-a3ea-46b4-d83f-85481a7dee97"
      },
      "source": [
        "# Deep Learning Fundamentals course\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# training parameters\n",
        "batch_size = 128\n",
        "img_size = 256\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "dropout = 0.5\n",
        "patience = 10\n",
        "\n",
        "def load_dataset(ds, mode):\n",
        "\n",
        "  def process_path(file_path):\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    one_hot = parts[-2] == class_names\n",
        "    label = tf.cast(one_hot, dtype='int64')  # Create labels\n",
        "    img = tf.io.read_file(file_path)  # Read file\n",
        "    img = tf.io.decode_jpeg(img, channels=3)  # Convert image to tensor\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32) # Normalize image in the range of 0 and 1\n",
        "    img = tf.image.resize(img, [img_size, img_size])    # Resize the image\n",
        "    return img, label\n",
        "\n",
        "  def transformation(image, label):\n",
        "    # Apply transformations to images \n",
        "    # the type of transformation (augmentations) used is different at train and evaluation time.\n",
        "    if mode == 'train':  \n",
        "      img = tf.image.central_crop(image, 0.7)\n",
        "      img = tf.image.resize_with_pad(img, img_size, img_size)\n",
        "      img = tf.clip_by_value(img, 0.0,1.0)    # To make sure images are in the range of 0 and 1 after transformations\n",
        "      return img, label\n",
        "    else:\n",
        "      img = tf.clip_by_value(image, 0.0,1.0) \n",
        "      return img, label\n",
        "\n",
        "  def configuration(dataset):\n",
        "    # Configurations to optimize the performance\n",
        "    dataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.map(transformation, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size=batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "  \n",
        "  # Load and generate dataset\n",
        "  data_dir = pathlib.Path(\"drive/MyDrive/dl/data/\" + ds) # Specify the path to data folder\n",
        "  image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "  files_list = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
        "  files_list = files_list.shuffle(image_count, reshuffle_each_iteration=False)\n",
        "  class_names = np.array(sorted([item.name for item in data_dir.glob('[!.]*')]))\n",
        "  print(\"Loading {} dataset!\".format(ds))\n",
        "  print(\"Number of classes: {}.\".format(len(class_names)))\n",
        "  print(\"Data size: {}.\".format(image_count))\n",
        "  print(\" ---------- --------- ---------- \\n\")\n",
        "  return configuration(files_list)\n",
        "\n",
        "# Prepare train and valid dataset\n",
        "train = load_dataset(ds = 'train', mode='train')\n",
        "valid = load_dataset(ds = 'valid', mode=None)\n",
        "\n",
        "# Create your own model or import pretrained models and add your own layers\n",
        "num_classes = 11\n",
        "\n",
        "vgg16_model = tf.keras.applications.vgg16.VGG16(include_top = False, weights = 'imagenet', pooling = 'maxpooling', input_shape = (img_size, img_size, 3))\n",
        "vgg16_model.summary()\n",
        "vgg16_model_touse = tf.keras.models.Model(inputs = vgg16_model.input, outputs= vgg16_model.get_layer('block5_pool').output)\n",
        "vgg16_model_touse.summary()\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  vgg16_model_touse,\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation = 'relu'),\n",
        "  tf.keras.layers.Conv2D(1024, (3, 3), activation = 'relu'),\n",
        "  tf.keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout),\n",
        "  tf.keras.layers.Dense(1024, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout),\n",
        "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# exclude the initial layers\n",
        "for layer in vgg16_model_touse.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Make sure to use h5 format to save model\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='min'), \n",
        "            ModelCheckpoint(filepath='model.h5', verbose=1, monitor='val_loss', save_best_only=True, save_weights_only=False, mode='min')]\n",
        "\n",
        "# data augmentation\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, horizontal_flip=True, shear_range=0.2, zoom_range=0.2, preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
        "valid_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
        "train_ds = train_generator.flow_from_directory('drive/MyDrive/dl/data/train', target_size = (img_size,img_size), batch_size = 200, class_mode = 'categorical')\n",
        "valid_ds = valid_generator.flow_from_directory('drive/MyDrive/dl/data/valid', target_size = (img_size,img_size), batch_size = 200, class_mode = 'categorical')\n",
        "\n",
        "# train the model\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  epochs = num_epochs,\n",
        "  validation_data = valid_ds,\n",
        "  callbacks = callbacks\n",
        ")\n",
        "\n",
        "# checking the history\n",
        "history_df = pd.DataFrame(history.history)\n",
        "print(history_df)\n",
        "history_csv_file = 'history.csv'\n",
        "with open(history_csv_file, mode = 'w') as f:\n",
        "  history_df.to_csv(history_csv_file)\n",
        "history_toread = np.loadtxt('history.csv', delimiter = ',', skiprows = 1)\n",
        "plt.plot(history.history['accuracy'], 'b-', label = 'accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'y-', label = 'val_accuracy')\n",
        "plt.plot(history.history['loss'], 'r-', label = 'loss')\n",
        "plt.plot(history.history['val_loss'], 'g-', label = 'val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train dataset!\n",
            "Number of classes: 11.\n",
            "Data size: 7213.\n",
            " ---------- --------- ---------- \n",
            "\n",
            "Loading valid dataset!\n",
            "Number of classes: 11.\n",
            "Data size: 1543.\n",
            " ---------- --------- ---------- \n",
            "\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_1 (Functional)         (None, 8, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 11)                363       \n",
            "=================================================================\n",
            "Total params: 43,041,739\n",
            "Trainable params: 28,327,051\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Found 7213 images belonging to 11 classes.\n",
            "Found 1543 images belonging to 11 classes.\n",
            "Epoch 1/100\n",
            "37/37 [==============================] - 170s 4s/step - loss: 2.4217 - accuracy: 0.1045 - val_loss: 2.2864 - val_accuracy: 0.1951\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.28639, saving model to model.h5\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 2.2830 - accuracy: 0.1629 - val_loss: 2.0766 - val_accuracy: 0.2767\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.28639 to 2.07665, saving model to model.h5\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 2.1717 - accuracy: 0.2170 - val_loss: 1.9804 - val_accuracy: 0.3104\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.07665 to 1.98042, saving model to model.h5\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 2.0713 - accuracy: 0.2581 - val_loss: 1.8805 - val_accuracy: 0.3338\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.98042 to 1.88051, saving model to model.h5\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 2.0526 - accuracy: 0.2561 - val_loss: 1.8834 - val_accuracy: 0.3234\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.88051\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 141s 4s/step - loss: 1.9830 - accuracy: 0.2850 - val_loss: 1.7851 - val_accuracy: 0.3688\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.88051 to 1.78510, saving model to model.h5\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.9059 - accuracy: 0.3031 - val_loss: 1.7224 - val_accuracy: 0.4161\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.78510 to 1.72245, saving model to model.h5\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.8725 - accuracy: 0.3460 - val_loss: 1.6703 - val_accuracy: 0.4180\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.72245 to 1.67030, saving model to model.h5\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.7664 - accuracy: 0.3838 - val_loss: 1.6046 - val_accuracy: 0.4563\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.67030 to 1.60458, saving model to model.h5\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.7168 - accuracy: 0.4138 - val_loss: 1.5400 - val_accuracy: 0.4744\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.60458 to 1.53997, saving model to model.h5\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.6754 - accuracy: 0.4319 - val_loss: 1.5270 - val_accuracy: 0.4841\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.53997 to 1.52699, saving model to model.h5\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.6602 - accuracy: 0.4332 - val_loss: 1.5337 - val_accuracy: 0.5010\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.52699\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.6120 - accuracy: 0.4478 - val_loss: 1.4966 - val_accuracy: 0.5029\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.52699 to 1.49661, saving model to model.h5\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.6004 - accuracy: 0.4658 - val_loss: 1.4991 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.49661\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.5264 - accuracy: 0.4741 - val_loss: 1.5159 - val_accuracy: 0.5016\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.49661\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.5357 - accuracy: 0.4783 - val_loss: 1.4503 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.49661 to 1.45030, saving model to model.h5\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.5145 - accuracy: 0.4865 - val_loss: 1.3675 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.45030 to 1.36749, saving model to model.h5\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.4464 - accuracy: 0.5192 - val_loss: 1.3796 - val_accuracy: 0.5580\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.36749\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.4422 - accuracy: 0.5253 - val_loss: 1.3171 - val_accuracy: 0.5762\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.36749 to 1.31709, saving model to model.h5\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.3844 - accuracy: 0.5387 - val_loss: 1.3609 - val_accuracy: 0.5574\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.31709\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.3446 - accuracy: 0.5541 - val_loss: 1.3690 - val_accuracy: 0.5826\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.31709\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.3334 - accuracy: 0.5672 - val_loss: 1.4475 - val_accuracy: 0.5535\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.31709\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.4210 - accuracy: 0.5385 - val_loss: 1.3809 - val_accuracy: 0.5878\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.31709\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.3059 - accuracy: 0.5874 - val_loss: 1.3383 - val_accuracy: 0.5749\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.31709\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.2674 - accuracy: 0.5891 - val_loss: 1.2934 - val_accuracy: 0.6014\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.31709 to 1.29342, saving model to model.h5\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.2474 - accuracy: 0.5961 - val_loss: 1.3347 - val_accuracy: 0.5904\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.29342\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.2713 - accuracy: 0.5967 - val_loss: 1.3101 - val_accuracy: 0.6079\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.29342\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.2117 - accuracy: 0.6060 - val_loss: 1.3477 - val_accuracy: 0.5891\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.29342\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.3292 - accuracy: 0.5719 - val_loss: 1.2585 - val_accuracy: 0.5962\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.29342 to 1.25848, saving model to model.h5\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 144s 4s/step - loss: 1.1959 - accuracy: 0.6168 - val_loss: 1.2966 - val_accuracy: 0.6157\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.25848\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.1793 - accuracy: 0.6239 - val_loss: 1.2531 - val_accuracy: 0.6124\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.25848 to 1.25305, saving model to model.h5\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.1405 - accuracy: 0.6215 - val_loss: 1.2850 - val_accuracy: 0.6131\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.25305\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.1130 - accuracy: 0.6483 - val_loss: 1.1979 - val_accuracy: 0.6235\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.25305 to 1.19787, saving model to model.h5\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.0887 - accuracy: 0.6506 - val_loss: 1.3204 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.19787\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.0922 - accuracy: 0.6469 - val_loss: 1.3220 - val_accuracy: 0.6325\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.19787\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.0989 - accuracy: 0.6484 - val_loss: 1.3098 - val_accuracy: 0.6273\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.19787\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.0573 - accuracy: 0.6610 - val_loss: 1.3438 - val_accuracy: 0.6325\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.19787\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 142s 4s/step - loss: 1.0555 - accuracy: 0.6558 - val_loss: 1.3136 - val_accuracy: 0.6228\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.19787\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.0491 - accuracy: 0.6663 - val_loss: 1.3337 - val_accuracy: 0.6254\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.19787\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.0891 - accuracy: 0.6538 - val_loss: 1.3646 - val_accuracy: 0.6312\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.19787\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 1.0530 - accuracy: 0.6684 - val_loss: 1.3697 - val_accuracy: 0.6377\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.19787\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 0.9838 - accuracy: 0.6832 - val_loss: 1.3988 - val_accuracy: 0.6487\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.19787\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 143s 4s/step - loss: 0.9908 - accuracy: 0.6825 - val_loss: 1.2983 - val_accuracy: 0.6338\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.19787\n",
            "Epoch 00043: early stopping\n",
            "        loss  accuracy  val_loss  val_accuracy\n",
            "0   2.421705  0.104533  2.286395      0.195075\n",
            "1   2.282987  0.162900  2.076648      0.276734\n",
            "2   2.171672  0.216969  1.980419      0.310434\n",
            "3   2.071300  0.258145  1.880513      0.333765\n",
            "4   2.052560  0.256065  1.883398      0.323396\n",
            "5   1.982954  0.285041  1.785098      0.368762\n",
            "6   1.905930  0.303064  1.722448      0.416073\n",
            "7   1.872473  0.346042  1.670302      0.418017\n",
            "8   1.766358  0.383752  1.604581      0.456254\n",
            "9   1.716766  0.413836  1.539966      0.474401\n",
            "10  1.675406  0.431859  1.526992      0.484122\n",
            "11  1.660164  0.433246  1.533677      0.500972\n",
            "12  1.612038  0.447803  1.496607      0.502916\n",
            "13  1.600442  0.465826  1.499114      0.512638\n",
            "14  1.526396  0.474144  1.515936      0.501620\n",
            "15  1.535736  0.478303  1.450296      0.526896\n",
            "16  1.514457  0.486483  1.367486      0.530784\n",
            "17  1.446450  0.519201  1.379642      0.558004\n",
            "18  1.442245  0.525302  1.317089      0.576150\n",
            "19  1.384352  0.538749  1.360923      0.557356\n",
            "20  1.344585  0.554138  1.369024      0.582631\n",
            "21  1.333388  0.567170  1.447513      0.553467\n",
            "22  1.420956  0.538472  1.380901      0.587816\n",
            "23  1.305892  0.587412  1.338303      0.574854\n",
            "24  1.267394  0.589075  1.293418      0.601426\n",
            "25  1.247391  0.596146  1.334704      0.590408\n",
            "26  1.271272  0.596700  1.310086      0.607907\n",
            "27  1.211689  0.605989  1.347734      0.589112\n",
            "28  1.329186  0.571884  1.258484      0.596241\n",
            "29  1.195886  0.616803  1.296582      0.615684\n",
            "30  1.179258  0.623874  1.253054      0.612443\n",
            "31  1.140490  0.621517  1.284959      0.613091\n",
            "32  1.113047  0.648274  1.197871      0.623461\n",
            "33  1.088669  0.650631  1.320414      0.616332\n",
            "34  1.092157  0.646888  1.322012      0.632534\n",
            "35  1.098935  0.648413  1.309808      0.627349\n",
            "36  1.057284  0.661029  1.343820      0.632534\n",
            "37  1.055540  0.655760  1.313646      0.622813\n",
            "38  1.049121  0.666297  1.333698      0.625405\n",
            "39  1.089057  0.653820  1.364564      0.631238\n",
            "40  1.052986  0.668377  1.369714      0.637719\n",
            "41  0.983802  0.683211  1.398818      0.648736\n",
            "42  0.990776  0.682518  1.298259      0.633830\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CmcfF1SxXFy",
        "outputId": "0a7d311d-6378-4392-9bc5-98f19dd8fecd"
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "img_size = 256\n",
        "\n",
        "# Get class names and index in a dictionary\n",
        "data_dir = pathlib.Path(\"drive/MyDrive/dl/data/train\") # Specify the path to train data folder\n",
        "d = {0: 'creamy_paste',\n",
        " 1: 'diced',\n",
        " 2: 'floured',\n",
        " 3: 'grated',\n",
        " 4: 'juiced',\n",
        " 5: 'jullienne',\n",
        " 6: 'mixed',\n",
        " 7: 'other',\n",
        " 8: 'peeled',\n",
        " 9: 'sliced',\n",
        " 10: 'whole'}\n",
        "\n",
        "# Load test images\n",
        "data_dir = pathlib.Path(\"drive/MyDrive/dl/data/test/test\") # Specify the path to test data folder\n",
        "image_count = len(list(data_dir.glob('*.jpg')))\n",
        "files_list = tf.data.Dataset.list_files(str(data_dir/'*'), shuffle=False)\n",
        "print(\"Loading test dataset \\nData size: {}\".format(image_count))\n",
        "\n",
        "def process_path(file_path):\n",
        "  img = tf.io.read_file(file_path)  # Read file\n",
        "  img = tf.io.decode_jpeg(img, channels=3)  # Convert image to tensor\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32) # Normalize image in the range of 0 and 1\n",
        "  img = tf.image.resize(img, [img_size, img_size])    # Resize the image\n",
        "  return img\n",
        "\n",
        "def transformation(image):\n",
        "  # Apply transformations to images\n",
        "  # the type of transformation (augmentations) used is different at train and evaluation time.\n",
        "\n",
        "  img = tf.clip_by_value(image, 0.0,1.0)    # To make sure images are in the range of 0 and 1 after transformations\n",
        "  return img\n",
        "\n",
        "# Process test images\n",
        "dataset = files_list.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.map(transformation, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.batch(batch_size=batch_size)\n",
        "\n",
        "# Load saved model\n",
        "new_model = tf.keras.models.load_model(\"model.h5\")\n",
        "\n",
        "# Predict\n",
        "pred = new_model.predict(dataset, verbose=1)\n",
        "preds = np.argmax(pred, axis=1)\n",
        "\n",
        "# Create dictionary of images and their predictions\n",
        "dictionary = {}\n",
        "count = 0\n",
        "for i in files_list:\n",
        "  path = i.numpy().decode('utf-8')\n",
        "  dictionary.update({path[5:]:d[preds[count]]})\n",
        "  count += 1\n",
        "\n",
        "with open(\"results.json\", \"w\") as outfile:\n",
        "  json.dump(dictionary, outfile) \n",
        "\n",
        "print(\"Json file saved.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test dataset \n",
            "Data size: 2163\n",
            "68/68 [==============================] - 145s 2s/step\n",
            "Json file saved.\n"
          ]
        }
      ]
    }
  ]
}